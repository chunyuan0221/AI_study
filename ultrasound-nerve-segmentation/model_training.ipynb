{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQNEJyH8UhzwKf9P2ZpRnp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunyuan0221/AI_study/blob/master/model_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFqXMb75lF-B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79
        },
        "outputId": "f791a6e7-5184-46c2-fe1c-51bf79cd126f"
      },
      "source": [
        "import os\n",
        "from skimage.transform import resize\n",
        "from skimage.io import imsave\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, Conv2DTranspose\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvFBr2WCl9ih",
        "colab_type": "code",
        "outputId": "f07b32fe-74ca-42b9-811f-0c76cd11fdae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "from google.colab import drive\n",
        "path = drive.mount('/content/drive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S38kZL0o3wvp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a462b6c2-b5a7-48a7-8afd-72dc83092cde"
      },
      "source": [
        "ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzxUyzwym6sJ",
        "colab_type": "code",
        "outputId": "522caec0-245f-4857-8012-d49b30795341",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "os.listdir('drive/My Drive/ai_study/ultrasound-nerve-segmentation')\n",
        "path = 'drive/My Drive/ai_study/ultrasound-nerve-segmentation/'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['imgs_id_test.npy',\n",
              " 'imgs_test.npy',\n",
              " 'imgs_train.npy',\n",
              " 'imgs_mask_train.npy',\n",
              " 'data.py',\n",
              " '__pycache__',\n",
              " 'weights.h5',\n",
              " 'imgs_mask_test.npy',\n",
              " 'preds',\n",
              " 'submission.csv',\n",
              " 'result_to_csv.ipynb',\n",
              " 'Data preprocess(ndarray說明).ipynb',\n",
              " 'model_training.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5RJbShE3nf4N",
        "colab_type": "code",
        "outputId": "965c5d3c-99ba-4f8b-c0de-cce4c65cf02d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd 'drive/My Drive/ai_study/ultrasound-nerve-segmentation/'"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ai_study/ultrasound-nerve-segmentation\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3Q6L_mfozme",
        "colab_type": "code",
        "outputId": "bd5af10b-d857-4686-d21b-ec4659919b48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'Data preprocess(ndarray說明).ipynb'   model_training.ipynb\n",
            " data.py                               \u001b[0m\u001b[01;34mpreds\u001b[0m/\n",
            " imgs_id_test.npy                      \u001b[01;34m__pycache__\u001b[0m/\n",
            " imgs_mask_test.npy                    result_to_csv.ipynb\n",
            " imgs_mask_train.npy                   submission.csv\n",
            " imgs_test.npy                         weights.h5\n",
            " imgs_train.npy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Avq5C4AhpLvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from data import load_train_data, load_test_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgOIk93fpQPH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "K.set_image_data_format('channels_last')  # TF dimension ordering in this code\n",
        "\n",
        "img_rows = 96\n",
        "img_cols = 96\n",
        "\n",
        "smooth = 1."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDIa6LBNpWHv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred):\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zp5X2m4spdXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "70Jdju0wpf-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_unet():\n",
        "  inputs = Input((img_rows, img_cols, 1))\n",
        "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "  conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "  pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "  conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "  pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "  conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "  pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(pool3)\n",
        "  conv4 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv4)\n",
        "  pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
        "\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(pool4)\n",
        "  conv5 = Conv2D(512, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "  up6 = concatenate([Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(conv5), conv4], axis=3)\n",
        "  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(up6)\n",
        "  conv6 = Conv2D(256, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "  up7 = concatenate([Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(conv6), conv3], axis=3)\n",
        "  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(up7)\n",
        "  conv7 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv7)\n",
        "\n",
        "  up8 = concatenate([Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(conv7), conv2], axis=3)\n",
        "  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(up8)\n",
        "  conv8 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv8)\n",
        "\n",
        "  up9 = concatenate([Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(conv8), conv1], axis=3)\n",
        "  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(up9)\n",
        "  conv9 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv9)\n",
        "\n",
        "  conv10 = Conv2D(1, (1, 1), activation='sigmoid')(conv9)\n",
        "\n",
        "  model = Model(inputs=[inputs], outputs=[conv10])\n",
        "\n",
        "  model.compile(optimizer=Adam(lr=1e-5), loss=dice_coef_loss, metrics=[dice_coef])\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09NCrxlmpsEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(imgs):\n",
        "    imgs_p = np.ndarray((imgs.shape[0], img_rows, img_cols), dtype=np.uint8)\n",
        "    for i in range(imgs.shape[0]):\n",
        "        imgs_p[i] = resize(imgs[i], (img_cols, img_rows), preserve_range=True)\n",
        "\n",
        "    imgs_p = imgs_p[..., np.newaxis]\n",
        "    return imgs_p"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSGCI_U8puUW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_predict():\n",
        "    print('-'*30)\n",
        "    print('Loading and preprocessing train data...')\n",
        "    print('-'*30)\n",
        "    imgs_train, imgs_mask_train = load_train_data()\n",
        "\n",
        "    imgs_train = preprocess(imgs_train)\n",
        "    imgs_mask_train = preprocess(imgs_mask_train)\n",
        "\n",
        "    imgs_train = imgs_train.astype('float32')\n",
        "    mean = np.mean(imgs_train)  # mean for data centering\n",
        "    std = np.std(imgs_train)  # std for data normalization\n",
        "\n",
        "    imgs_train -= mean\n",
        "    imgs_train /= std\n",
        "\n",
        "    imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "    imgs_mask_train /= 255.  # scale masks to [0, 1]\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Creating and compiling model...')\n",
        "    print('-'*30)\n",
        "    model = get_unet()\n",
        "    model_checkpoint = ModelCheckpoint('weights.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Fitting model...')\n",
        "    print('-'*30)\n",
        "    model.fit(imgs_train, imgs_mask_train, batch_size=32, nb_epoch=20, verbose=1, shuffle=True,\n",
        "              validation_split=0.2,\n",
        "              callbacks=[model_checkpoint])\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Loading and preprocessing test data...')\n",
        "    print('-'*30)\n",
        "    imgs_test, imgs_id_test = load_test_data()\n",
        "    imgs_test = preprocess(imgs_test)\n",
        "\n",
        "    imgs_test = imgs_test.astype('float32')\n",
        "    imgs_test -= mean\n",
        "    imgs_test /= std\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Loading saved weights...')\n",
        "    print('-'*30)\n",
        "    model.load_weights('weights.h5')\n",
        "\n",
        "    print('-'*30)\n",
        "    print('Predicting masks on test data...')\n",
        "    print('-'*30)\n",
        "    imgs_mask_test = model.predict(imgs_test, verbose=1)\n",
        "    np.save('imgs_mask_test.npy', imgs_mask_test)\n",
        "\n",
        "    print('-' * 30)\n",
        "    print('Saving predicted masks to files...')\n",
        "    print('-' * 30)\n",
        "    pred_dir = 'preds'\n",
        "    if not os.path.exists(pred_dir):\n",
        "        os.mkdir(pred_dir)\n",
        "    for image, image_id in zip(imgs_mask_test, imgs_id_test):\n",
        "        image = (image[:, :, 0] * 255.).astype(np.uint8)\n",
        "        imsave(os.path.join(pred_dir, str(image_id) + '_pred.png'), image)\n",
        "    print('-' * 30)\n",
        "    print('Done')\n",
        "    print('-' * 30)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "In-4sbWLpzpe",
        "colab_type": "code",
        "outputId": "9d89916c-3bf6-4bea-e7ad-b9b16ed641ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import warnings\n",
        "warnings.simplefilter(\"ignore\", UserWarning)\n",
        "\n",
        "train_and_predict()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------\n",
            "Loading and preprocessing train data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Creating and compiling model...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Fitting model...\n",
            "------------------------------\n",
            "Train on 4508 samples, validate on 1127 samples\n",
            "Epoch 1/20\n",
            "4508/4508 [==============================] - 24s 5ms/step - loss: -0.0248 - dice_coef: 0.0248 - val_loss: -0.0196 - val_dice_coef: 0.0196\n",
            "Epoch 2/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.0423 - dice_coef: 0.0423 - val_loss: -0.0502 - val_dice_coef: 0.0502\n",
            "Epoch 3/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.2275 - dice_coef: 0.2275 - val_loss: -0.1784 - val_dice_coef: 0.1784\n",
            "Epoch 4/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.2833 - dice_coef: 0.2833 - val_loss: -0.2029 - val_dice_coef: 0.2029\n",
            "Epoch 5/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.3446 - dice_coef: 0.3446 - val_loss: -0.1935 - val_dice_coef: 0.1935\n",
            "Epoch 6/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.3812 - dice_coef: 0.3812 - val_loss: -0.2727 - val_dice_coef: 0.2727\n",
            "Epoch 7/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4195 - dice_coef: 0.4195 - val_loss: -0.3105 - val_dice_coef: 0.3105\n",
            "Epoch 8/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4431 - dice_coef: 0.4431 - val_loss: -0.3012 - val_dice_coef: 0.3012\n",
            "Epoch 9/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4523 - dice_coef: 0.4523 - val_loss: -0.2950 - val_dice_coef: 0.2950\n",
            "Epoch 10/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4752 - dice_coef: 0.4752 - val_loss: -0.3265 - val_dice_coef: 0.3265\n",
            "Epoch 11/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4869 - dice_coef: 0.4869 - val_loss: -0.3405 - val_dice_coef: 0.3405\n",
            "Epoch 12/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.4998 - dice_coef: 0.4998 - val_loss: -0.3630 - val_dice_coef: 0.3630\n",
            "Epoch 13/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5087 - dice_coef: 0.5087 - val_loss: -0.3514 - val_dice_coef: 0.3514\n",
            "Epoch 14/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5266 - dice_coef: 0.5266 - val_loss: -0.3496 - val_dice_coef: 0.3496\n",
            "Epoch 15/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5323 - dice_coef: 0.5323 - val_loss: -0.3733 - val_dice_coef: 0.3733\n",
            "Epoch 16/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5407 - dice_coef: 0.5407 - val_loss: -0.3721 - val_dice_coef: 0.3721\n",
            "Epoch 17/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5445 - dice_coef: 0.5445 - val_loss: -0.3666 - val_dice_coef: 0.3666\n",
            "Epoch 18/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5552 - dice_coef: 0.5552 - val_loss: -0.3540 - val_dice_coef: 0.3540\n",
            "Epoch 19/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5550 - dice_coef: 0.5550 - val_loss: -0.3089 - val_dice_coef: 0.3089\n",
            "Epoch 20/20\n",
            "4508/4508 [==============================] - 8s 2ms/step - loss: -0.5608 - dice_coef: 0.5608 - val_loss: -0.3869 - val_dice_coef: 0.3869\n",
            "------------------------------\n",
            "Loading and preprocessing test data...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Loading saved weights...\n",
            "------------------------------\n",
            "------------------------------\n",
            "Predicting masks on test data...\n",
            "------------------------------\n",
            "5508/5508 [==============================] - 3s 595us/step\n",
            "------------------------------\n",
            "Saving predicted masks to files...\n",
            "------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
